{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sklearn packages\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, RocCurveDisplay, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Grandient Boosted CARTs:\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "#SHAP\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'xyz.csv'\n",
    "df = pd.read_csv(filename, sep = ',')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for features with null values:\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fill null values with 0 (Other imputation methods could also be explored)\n",
    "df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sometimes columns can have values that should be replaced with other values\n",
    "df['A'] = df['A'].apply(lambda x: 'string' if x == 'xyz' else x)\n",
    "\n",
    "### NLP techniques could also be used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot encoding:\n",
    "df = pd.get_dummies(df[['A', 'B', 'C']])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm the one-hot encoding\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into categorical and numerical features:\n",
    "df_cat = df.select_dtypes(include = ['object', 'bool'])\n",
    "df_cat_columns = df_cat.columns\n",
    "\n",
    "df_num = df.select_dtypes(include = ['int8', 'int32', 'float64'])\n",
    "df_num_columns = df_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some categories need simple label encoding:\n",
    "df_encoded = pd.DataFrame()\n",
    "\n",
    "for category in df_cat_columns:\n",
    "    le.fit(df[category])\n",
    "    encoded_cat = le.transform(df[category])\n",
    "    encoded_cat = pd.DataFrame(encoded_cat)\n",
    "    df_encoded = pd.concat([df_encoded, encoded_cat], axis = 1)\n",
    "\n",
    "df_encoded.columns = df_cat_columns\n",
    "df_encoded = pd.concat([df_encoded, df_num], axis = 1)\n",
    "\n",
    "df_encoded = df_encoded.drop(['A', 'B', 'C'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train-test-split\n",
    "y = df_encoded['TARGET']\n",
    "X = df_encoded.drop(['TARGET'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21, stratify=y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if the target values are balanced:\n",
    "df_encoded['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Catboost classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### If data is imbalanced you can adjsut class_weights parameter\n",
    "class_weights = [1,1]\n",
    "\n",
    "catboost = CatBoostClassifier(silent = True, n_estimators = 100, learning_rate = 0.05, class_weights = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification performance and Confusion Matrix\n",
    "\n",
    "y_pred = catboost.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_prest, labels = catboost.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=catboost.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using SHAP to calculate features importance:\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(catboost)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, features = X_test, feature_names = X_test.columns)\n",
    "shap.summary_plot(shap_values, features = X_test, feature_names = X_test.columns, plot_type = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating the AUC-ROC curve:\n",
    "\n",
    "y_probs = pd.DataFarme(catboost.predict_proba(X_test)[[1]])\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_probs,\n",
    "    name = f\"ROC\"\n",
    "    color = \"darkorange\"\n",
    ")\n",
    "plt.plot([0,1], [0,1], \"k--\", label = \"chance level (AUC = 0.5)\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC curves:\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "auc = np.round(roc_auc_score(y_test, y_probs), 2)\n",
    "print(auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
