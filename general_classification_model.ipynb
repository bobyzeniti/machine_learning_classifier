{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sklearn packages\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, RocCurveDisplay, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Grandient Boosted CARTs:\n",
    "#import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "#SHAP\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'xyz.csv'\n",
    "df = pd.read_csv(filename, sep = ',')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for features with null values:\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fill null values with 0 (Other imputation methods could also be explored)\n",
    "df.fillna(0, inplace = True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sometimes columns can have values that should be replaced with other values\n",
    "df['A'] = df['A'].apply(lambda x: 'string' if x == 'xyz' else x)\n",
    "\n",
    "### NLP techniques could also be used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop features not used for training. For example, identification keys for dataset instances, names, etc...:\n",
    "df_ids = df[['IDENTIFICATION_KEY']]\n",
    "df.drop(['IDENTIFICATION_KEY'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple label encoder:\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot encoding of cardinal categories, where there is no ordinal relationship between the categories:\n",
    "df_one_hot_encoded = pd.get_dummies(df[['A', 'B', 'C']])\n",
    "df = df.drop(['A', 'B', 'C'], axis = 1)\n",
    "  \n",
    "df = pd.concat([df, df_one_hot_encoded], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm the one-hot encoding\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into categorical and numerical features:\n",
    "### In some datasets it might be necessary to perform reset_index() and then delete the index column created:\n",
    "df_cat = df.select_dtypes(include = ['object', 'bool'])\n",
    "df_cat_columns = df_cat.columns\n",
    "\n",
    "df_num = df.select_dtypes(include = ['int8', 'int32', 'float64'])\n",
    "df_num_columns = df_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some categories need simple label encoding:\n",
    "df_encoded = pd.DataFrame()\n",
    "\n",
    "for category in df_cat_columns:\n",
    "    le.fit(df[category])\n",
    "    print(\"Original category values for {}: {}\".format(category, le.classes_))\n",
    "    print(le.transform(le.classes_))\n",
    "    encoded_cat = le.transform(df[category])\n",
    "    encoded_cat = pd.DataFrame(encoded_cat)\n",
    "    df_encoded = pd.concat([df_encoded, encoded_cat], axis = 1)\n",
    "\n",
    "df_encoded.columns = df_cat_columns\n",
    "df_encoded = pd.concat([df_encoded, df_num], axis = 1)\n",
    "\n",
    "#Drop the original categories that were one-hot encoded and are no longer necessary:\n",
    "df_encoded = df_encoded.drop(['A', 'B', 'C'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train-test-split (Usually test size is 20%) with stratification:\n",
    "y = df_encoded['TARGET']\n",
    "X = df_encoded.drop(['TARGET'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21, stratify=y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if the target values are balanced:\n",
    "df_encoded['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary with several different models to be tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the cross validation to analyze the bias-variance of results and do the apply proper regularization:\n",
    "kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "#This dictionary can be used to implement several different classifiers to be tested:\n",
    "models = {'cat_boost': CatBoostClassifier(silent = True, n_estimators = 1000, \\\n",
    "                                            learning_rate = 0.045, max_depth = 3, random_state = 42, l2_leaf_reg = 0.1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit and evaluate each model:\n",
    "for model in models.values():\n",
    "    if type(model) ==  type(CatBoostClassifier()):\n",
    "        clf = model\n",
    "        print(model)\n",
    "        steps = [('classifier', clf)]\n",
    "        pipeline = Pipeline(steps)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        #Print the k-fold cross-validation results on the selected metric (e.g. \"Recall\")\n",
    "        print(cross_val_score(pipeline, X_train, y_train, cv = kf, scoring = 'recall'))\n",
    "        print(np.mean(cross_val_score(pipeline, X_train, y_train, cv = kf, scoring = 'recall')))\n",
    "\n",
    "        #Predictions and Classification Report:\n",
    "        y_train_pred = pipeline.predict(X_train)\n",
    "        print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After evaluating the results above, select a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### If data is imbalanced you can adjsut class_weights parameter\n",
    "class_weights = [1,1]\n",
    "n_estimators = 1000\n",
    "learning_rate = 0.05\n",
    "\n",
    "selected_model = CatBoostClassifier(silent = True, n_estimators = n_estimators, learning_rate = learning_rate, class_weights = class_weights)\n",
    "\n",
    "selected_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification performance and Confusion Matrix\n",
    "\n",
    "y_pred = selected_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plt.clf()\n",
    "cm = confusion_matrix(y_test, y_prest, labels = selected_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=selected_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final part of this notebook is to calculate the Feature Importance.\n",
    "### SHAP scores will be used to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using SHAP to calculate features importance:\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(selected_model)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, features = X_test, feature_names = X_test.columns)\n",
    "shap.summary_plot(shap_values, features = X_test, feature_names = X_test.columns, plot_type = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, AUC-ROC will be used as a final evaluation of model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating the AUC-ROC curve for testing and training sets:\n",
    "\n",
    "y_probs_test = pd.DataFarme(selected_model.predict_proba(X_test)[[1]])\n",
    "y_probs_train = pd.DataFarme(selected_model.predict_proba(X_train)[[1]])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "train = RocCurveDisplay.from_predictions(\n",
    "    y_train,\n",
    "    y_probs_train,\n",
    "    name = f\"ROC train\"\n",
    "    color = \"blue\"\n",
    ")\n",
    "\n",
    "test = RocCurveDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_probs,\n",
    "    name = f\"ROC test\"\n",
    "    color = \"darkorange\"\n",
    ")\n",
    "\n",
    "plt.plot([0,1], [0,1], \"k--\", label = \"chance level (AUC = 0.5)\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC curves:\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "auc = np.round(roc_auc_score(y_test, y_probs), 2)\n",
    "print(auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
